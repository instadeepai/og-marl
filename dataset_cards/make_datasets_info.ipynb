{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from og_marl.vault_utils.download_vault import *\n",
    "from og_marl.vault_utils.analyse_vault import *\n",
    "import os\n",
    "import json\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_vaults = print_download_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datacard_info(\n",
    "    vault_name: str,\n",
    "    rel_dir: str = \"vaults\",\n",
    "    done_flags: tuple = (\"terminals\",),\n",
    ") -> Dict[str, Array]:\n",
    "    \n",
    "    out_info = {}\n",
    "    \n",
    "    vault_uids = get_available_uids(f\"./{rel_dir}/{vault_name}\")\n",
    "\n",
    "    for uid in vault_uids:\n",
    "        out_info[uid] = {}\n",
    "\n",
    "        vlt = Vault(vault_name=vault_name, rel_dir=rel_dir, vault_uid=uid)\n",
    "        exp = vlt.read().experience\n",
    "\n",
    "        saco, _, _ = get_saco(exp)\n",
    "        mean, stddev, max_ret, min_ret, episode_returns = get_episode_return_descriptors(exp, done_flags)\n",
    "        n_trans = exp[\"actions\"].shape[1]\n",
    "\n",
    "        struct, _, n_traj = get_structure_descriptors(exp, 0, done_flags)\n",
    "\n",
    "        out_info[uid][\"Mean episode return\"] = float(mean)\n",
    "        out_info[uid][\"Standard deviation episode return\"] = float(stddev)\n",
    "        out_info[uid][\"Min return\"] = float(min_ret)\n",
    "        out_info[uid][\"Max return\"] = float(max_ret)\n",
    "        out_info[uid][\"Transitions\"] = n_trans\n",
    "        out_info[uid][\"Trajectories\"] = n_traj\n",
    "        out_info[uid][\"Joint SACo\"] = saco\n",
    "        out_info[uid][\"Structure\"] = struct\n",
    "\n",
    "    return out_info, vault_uids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"../docs/dataset_cards/datacard_info.json\") as current_info:\n",
    "    # get json string\n",
    "    datacard_str = json.load(current_info)\n",
    "\n",
    "    # convert to dictionary\n",
    "    datacard_dict = json.loads(datacard_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pretty names to print for these\n",
    "env_add_info = {\n",
    "    \"mamujoco\": {\"pretty_name\":\"MAMuJoCo\", \"action_space\": \"Continuous\"},\n",
    "    \"smac_v1\": {\"pretty_name\":\"SMAC (v1)\", \"action_space\": \"Discrete\"},\n",
    "    \"smac_v2\": {\"pretty_name\":\"SMAC (v2)\", \"action_space\": \"Discrete\"},\n",
    "    \"mpe\" : {\"pretty_name\":\"MPE\", \"action_space\": \"Continuous\"},\n",
    "    \"rware\": {\"pretty_name\":\"RWARE\", \"action_space\": \"Discrete\"},\n",
    "}\n",
    "\n",
    "ogmarl_collecting_policy = {\n",
    "    \"smac_v1\": \"QMIX\",\n",
    "    \"smac_v2\": \"QMIX\",\n",
    "    \"mamujoco\": \"MATD3\",\n",
    "\n",
    "}\n",
    "\n",
    "add_diversity_explanation = {\n",
    "    \"Continuous\":\"Gaussian noise with standard deviation of 0.2 was added to the action selection.\",\n",
    "    \"Discrete\":\"An epsilon greedy policy with eps=0.05 was used.\",\n",
    "}\n",
    "\n",
    "# datacard_dict_update = \n",
    "\n",
    "for source in available_vaults.keys():\n",
    "    datacard_dict[source] = {}\n",
    "    for env in available_vaults[source].keys():\n",
    "        datacard_dict[source][env] = {}\n",
    "        if not env==\"gymnasium_mamujoco\":\n",
    "            for task in available_vaults[source][env].keys():\n",
    "\n",
    "                datacard_dict[source][env][task] = {}\n",
    "                \n",
    "                # download vault\n",
    "                rel_vault_location = download_and_unzip_vault(source,env,task)\n",
    "\n",
    "                # convert source-env-task naming convention to rel_dir-vault_name-vault_uids categories\n",
    "                vault_rel_dir = f\"vaults/{source}/{env}\"\n",
    "                vault_name = f\"{task}.vlt\" # a vault name contains only the file name which has the .vlt extension\n",
    "\n",
    "                out_info, vault_uids = make_datacard_info(vault_name=vault_name,rel_dir=vault_rel_dir)\n",
    "\n",
    "                datacard_dict[source][env][task].update(out_info)\n",
    "\n",
    "\n",
    "                for uid in vault_uids:\n",
    "                    datacard_dict[source][env][task][uid][\"Download link\"] = available_vaults[source][env][task][\"url\"]\n",
    "                    datacard_dict[source][env][task][uid][\"Scenario name\"] = task\n",
    "                    datacard_dict[source][env][task][uid][\"Dataset name\"] = uid\n",
    "                    datacard_dict[source][env][task][uid][\"Environment name\"] = env_add_info[env][\"pretty_name\"]\n",
    "                    datacard_dict[source][env][task][uid][\"Action space\"] = env_add_info[env][\"action_space\"]\n",
    "                    if not (source==\"og_marl\"):\n",
    "                        datacard_dict[source][env][task][uid][\"Motivation\"] = \"Existing dataset from the literature converted to Vault format for accessibility.\"\n",
    "                        datacard_dict[source][env][task][uid][\"Generation procedure\"] = f\"Converted from {source} format to a Vault.\"\n",
    "                        datacard_dict[source][env][task][uid][\"Histogram download url\"] = f\"https://raw.huggingface.co/datasets/InstaDeepAI/og-marl/resolve/main/prior_work/{source}/{env}/{task}_histogram.pdf\"\n",
    "\n",
    "                    else:\n",
    "                        datacard_dict[source][env][task][uid][\"Histogram download url\"] = f\"https://raw.huggingface.co/datasets/InstaDeepAI/og-marl/resolve/main/core/{env}/{task}_histogram.pdf\"\n",
    "                        if not (uid==\"Replay\"):\n",
    "                            datacard_dict[source][env][task][uid][\"Generation procedure\"] = f\"A {ogmarl_collecting_policy[env]} system was trained to target level of performance. The learnt policy was then rolled out to collect approximately 250k transitions. {add_diversity_explanation[env_add_info[env]['action_space']]} This procedure was repeated 4 times and the data was combined.\"\n",
    "                        else:\n",
    "                            datacard_dict[source][env][task][uid][\"Generation procedure\"] = f\"A {ogmarl_collecting_policy[env]} system was trained to target level of performance. The learnt policy was then rolled out to collect approximately 1m transitions. {add_diversity_explanation[env_add_info[env]['action_space']]}\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"../docs/dataset_cards/datacard_info.json\",\"w\") as current_info:\n",
    "    # convert to json string\n",
    "    datacard_str = json.dumps(datacard_dict,indent=4)\n",
    "\n",
    "    # save dictionary\n",
    "    json.dump(datacard_str,current_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "og-marl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
